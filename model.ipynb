{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09d60b32-1929-4016-a499-115e1791047d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing CNN preprocessor...\n",
      "Using device: cpu\n",
      "\n",
      "Processing male images:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Male Images: 100%|█████████████████████████████████████████████████████████████████| 1000/1000 [00:46<00:00, 21.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing female images:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Female Images:  79%|██████████████████████████████████████████████████▎             | 787/1000 [00:48<00:18, 11.62it/s]C:\\Users\\khadija\\anaconda4\\envs\\newenv\\lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Female Images: 100%|███████████████████████████████████████████████████████████████| 1000/1000 [00:58<00:00, 17.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing data...\n",
      "Final dataset shape - X: (2000, 8192), y: (2000, 1)\n",
      "\n",
      "Saving processed features...\n"
     ]
    }
   ],
   "source": [
    "# Part 1: CNN Preprocessor \n",
    "# IN THIS PART IS FOR CNN preprocessing and saving the features\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "class CNNPreprocessor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNPreprocessor, self).__init__()\n",
    "        # # CNN layers\n",
    "        # I USED 2 Bocks with conventional layers \n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "def process_image_cnn(image_path, cnn_model):\n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        img = Image.open(image_path).convert('L')\n",
    "        img = img.resize((64, 64))\n",
    "        # Convert to tensor and add batch and channel dimensions\n",
    "        img_tensor = torch.tensor(np.array(img), dtype=torch.float32) / 255.0\n",
    "        img_tensor = img_tensor.unsqueeze(0).unsqueeze(0)\n",
    "        # Pass through CNN\n",
    "        with torch.no_grad():\n",
    "            cnn_features = cnn_model(img_tensor)\n",
    "        # Convert to numpy array\n",
    "        return cnn_features.numpy().T\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_and_save_features(men_dir, women_dir, max_images_per_class=None):\n",
    "    print(\"Initializing CNN preprocessor...\")\n",
    "    cnn_model = CNNPreprocessor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    cnn_model = cnn_model.to(device)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Process male images\n",
    "    print(\"\\nProcessing male images:\")\n",
    "    male_files = [f for f in os.listdir(men_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if max_images_per_class:\n",
    "        male_files = male_files[:max_images_per_class]\n",
    "        \n",
    "    for filename in tqdm(male_files, desc=\"Male Images\"):\n",
    "        img_path = os.path.join(men_dir, filename)\n",
    "        cnn_features = process_image_cnn(img_path, cnn_model)\n",
    "        if cnn_features is not None:\n",
    "            X.append(cnn_features)\n",
    "            y.append(np.array([[1]]))\n",
    "    \n",
    "    # Process female images\n",
    "    print(\"\\nProcessing female images:\")\n",
    "    female_files = [f for f in os.listdir(women_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if max_images_per_class:\n",
    "        female_files = female_files[:max_images_per_class]\n",
    "        \n",
    "    for filename in tqdm(female_files, desc=\"Female Images\"):\n",
    "        img_path = os.path.join(women_dir, filename)\n",
    "        cnn_features = process_image_cnn(img_path, cnn_model)\n",
    "        if cnn_features is not None:\n",
    "            X.append(cnn_features)\n",
    "            y.append(np.array([[0]]))\n",
    "    \n",
    "    print(\"\\nPreparing data...\")\n",
    "    # Stack features and transpose correctly\n",
    "    X = np.hstack(X)  # Concatenate along horizontal axis\n",
    "    X = X.T          # Transpose to get (samples, features)\n",
    "    y = np.vstack(y)  # Stack labels vertically\n",
    "    \n",
    "    print(f\"Final dataset shape - X: {X.shape}, y: {y.shape}\")\n",
    "    \n",
    "    # Save processed features\n",
    "    print(\"\\nSaving processed features...\")\n",
    "    with open('processed_features.pkl', 'wb') as f:\n",
    "        pickle.dump((X, y), f)\n",
    "    \n",
    "    return X, y\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    men_dir = 'content/male_faces'\n",
    "    women_dir = 'content/female_faces'\n",
    "    # I HAD PROBLEMS RUNNING THE MODEL BECAUSE of  RAM so i decided to only use half of the data \n",
    "    # Process only half of the data\n",
    "    max_images = 1000  # Adjust this number as needed\n",
    "    \n",
    "    # Process and save features\n",
    "    X, y = process_and_save_features(men_dir, women_dir, max_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "863d0138-6e9f-4be7-865e-53032998c723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khadija\\anaconda4\\envs\\newenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed features...\n",
      "\n",
      "Diagnostic information:\n",
      "X shape: (2000, 8192)\n",
      "y shape: (2000, 1)\n",
      "X dtype: float32\n",
      "y dtype: int32\n",
      "\n",
      "Initializing neural network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|███████████████████████████████| 100/100 [09:35<00:00,  5.75s/it, Cost=0.4194, Accuracy=83.40%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model parameters...\n",
      "Training completed and model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 2: Neural Network \n",
    "# I THIS IS FOR oading those features and training the model.\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "def initialiser(dimensions):\n",
    "    parameters = {}\n",
    "    C = len(dimensions)\n",
    "    for c in range(1, C):\n",
    "        parameters['W' + str(c)] = np.random.randn(dimensions[c], dimensions[c-1]) * np.sqrt(2./dimensions[c-1])\n",
    "        parameters['b' + str(c)] = np.zeros((dimensions[c], 1))\n",
    "    return parameters\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    activations = {\"A0\": X.T}\n",
    "    C = len(parameters) // 2\n",
    "    for c in range(1, C + 1):\n",
    "        Z = parameters['W' + str(c)].dot(activations['A' + str(c - 1)]) + parameters['b' + str(c)]\n",
    "        if c < C:\n",
    "            activations['A' + str(c)] = np.maximum(0, Z)\n",
    "        else:\n",
    "            activations['A' + str(c)] = 1 / (1 + np.exp(-Z))\n",
    "    return activations\n",
    "\n",
    "def back_propagation(y, parameters, activations):\n",
    "    gradients = {}\n",
    "    C = len(parameters) // 2\n",
    "    m = y.shape[0]\n",
    "    y = y.T\n",
    "    \n",
    "    dZ = activations['A' + str(C)] - y\n",
    "    for c in reversed(range(1, C + 1)):\n",
    "        gradients['dW' + str(c)] = (1/m) * np.dot(dZ, activations['A' + str(c - 1)].T)\n",
    "        gradients['db' + str(c)] = (1/m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "        if c > 1:\n",
    "            dA_prev = np.dot(parameters['W' + str(c)].T, dZ)\n",
    "            dZ = dA_prev * (activations['A' + str(c-1)] > 0)\n",
    "    return gradients\n",
    "\n",
    "def update(gradients, parameters, learning_rate):\n",
    "    C = len(parameters) // 2\n",
    "    for c in range(1, C + 1):\n",
    "        parameters['W' + str(c)] = parameters['W' + str(c)] - learning_rate * gradients['dW' + str(c)]\n",
    "        parameters['b' + str(c)] = parameters['b' + str(c)] - learning_rate * gradients['db' + str(c)]\n",
    "    return parameters\n",
    "\n",
    "def deep_learning(X, y, hidden_layers=(16, 16, 16), learning_rate=0.01, n_iter=1000, batch_size=32):\n",
    "    print(\"\\nInitializing neural network...\")\n",
    "    n_features = X.shape[1]\n",
    "    dimensions = [n_features] + list(hidden_layers) + [1]\n",
    "    \n",
    "    parameters = initialiser(dimensions)\n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    if len(y.shape) == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "    \n",
    "    progress_bar = tqdm(range(n_iter), desc=\"Training Progress\")\n",
    "    costs = []\n",
    "    \n",
    "    for i in progress_bar:\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        epoch_cost = 0\n",
    "        \n",
    "        for j in range(0, n_samples, batch_size):\n",
    "            batch_indices = indices[j:min(j + batch_size, n_samples)]\n",
    "            X_batch = X[batch_indices]\n",
    "            y_batch = y[batch_indices]\n",
    "            \n",
    "            activations = forward_propagation(X_batch, parameters)\n",
    "            gradients = back_propagation(y_batch, parameters, activations)\n",
    "            parameters = update(gradients, parameters, learning_rate)\n",
    "            \n",
    "            output = activations[f'A{len(hidden_layers) + 1}']\n",
    "            batch_cost = -np.mean(y_batch.T * np.log(output + 1e-8) + \n",
    "                                (1 - y_batch.T) * np.log(1 - output + 1e-8))\n",
    "            epoch_cost += batch_cost * len(batch_indices)\n",
    "        \n",
    "        epoch_cost /= n_samples\n",
    "        costs.append(epoch_cost)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            activations = forward_propagation(X, parameters)\n",
    "            output_layer_activation = activations[f'A{len(hidden_layers) + 1}']\n",
    "            accuracy = np.mean((output_layer_activation.T >= 0.5) == y)\n",
    "            progress_bar.set_postfix({'Cost': f'{epoch_cost:.4f}', 'Accuracy': f'{accuracy:.2%}'})\n",
    "    \n",
    "    return parameters, costs\n",
    "   # Load the processed features\n",
    "print(\"Loading processed features...\")\n",
    "with open('processed_features.pkl', 'rb') as f:\n",
    "    X, y = pickle.load(f)\n",
    "\n",
    "# Print diagnostic information\n",
    "print(\"\\nDiagnostic information:\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"X dtype:\", X.dtype)\n",
    "print(\"y dtype:\", y.dtype)\n",
    "\n",
    "# Train the model\n",
    "parameters, costs = deep_learning(\n",
    "    X, \n",
    "    y, \n",
    "    hidden_layers=(256, 128, 64),\n",
    "    learning_rate=0.001,\n",
    "    n_iter=100,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "print(\"\\nSaving model parameters...\")\n",
    "with open('model_parameters.pkl', 'wb') as f:\n",
    "    pickle.dump((parameters, costs), f)\n",
    "\n",
    "print(\"Training completed and model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c31a08a-42e5-4d69-944d-bfdf4b6f0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I didn't like the result so i trained my model again BY CHANGING  the number of iteration  to get a BETTER  accuracy AND MINIMISE MORE THE cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51617ef-859f-4631-96e2-0a108b4721ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed features...\n",
      "\n",
      "Diagnostic information:\n",
      "X shape: (2000, 8192)\n",
      "y shape: (2000, 1)\n",
      "X dtype: float32\n",
      "y dtype: int32\n",
      "\n",
      "Initializing neural network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|███████████████████████████████| 500/500 [47:55<00:00,  5.75s/it, Cost=0.1023, Accuracy=99.90%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model parameters...\n",
      "Training completed and model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 2: Neural Network \n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "def initialiser(dimensions):\n",
    "    parameters = {}\n",
    "    C = len(dimensions)\n",
    "    for c in range(1, C):\n",
    "        parameters['W' + str(c)] = np.random.randn(dimensions[c], dimensions[c-1]) * np.sqrt(2./dimensions[c-1])\n",
    "        parameters['b' + str(c)] = np.zeros((dimensions[c], 1))\n",
    "    return parameters\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    activations = {\"A0\": X.T}\n",
    "    C = len(parameters) // 2\n",
    "    for c in range(1, C + 1):\n",
    "        Z = parameters['W' + str(c)].dot(activations['A' + str(c - 1)]) + parameters['b' + str(c)]\n",
    "        if c < C:\n",
    "            activations['A' + str(c)] = np.maximum(0, Z)\n",
    "        else:\n",
    "            activations['A' + str(c)] = 1 / (1 + np.exp(-Z))\n",
    "    return activations\n",
    "\n",
    "def back_propagation(y, parameters, activations):\n",
    "    gradients = {}\n",
    "    C = len(parameters) // 2\n",
    "    m = y.shape[0]\n",
    "    y = y.T\n",
    "    \n",
    "    dZ = activations['A' + str(C)] - y\n",
    "    for c in reversed(range(1, C + 1)):\n",
    "        gradients['dW' + str(c)] = (1/m) * np.dot(dZ, activations['A' + str(c - 1)].T)\n",
    "        gradients['db' + str(c)] = (1/m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "        if c > 1:\n",
    "            dA_prev = np.dot(parameters['W' + str(c)].T, dZ)\n",
    "            dZ = dA_prev * (activations['A' + str(c-1)] > 0)\n",
    "    return gradients\n",
    "\n",
    "def update(gradients, parameters, learning_rate):\n",
    "    C = len(parameters) // 2\n",
    "    for c in range(1, C + 1):\n",
    "        parameters['W' + str(c)] = parameters['W' + str(c)] - learning_rate * gradients['dW' + str(c)]\n",
    "        parameters['b' + str(c)] = parameters['b' + str(c)] - learning_rate * gradients['db' + str(c)]\n",
    "    return parameters\n",
    "\n",
    "def deep_learning(X, y, hidden_layers=(16, 16, 16), learning_rate=0.01, n_iter=1000, batch_size=32):\n",
    "    print(\"\\nInitializing neural network...\")\n",
    "    n_features = X.shape[1]\n",
    "    dimensions = [n_features] + list(hidden_layers) + [1]\n",
    "    \n",
    "    parameters = initialiser(dimensions)\n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    if len(y.shape) == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "    \n",
    "    progress_bar = tqdm(range(n_iter), desc=\"Training Progress\")\n",
    "    costs = []\n",
    "    \n",
    "    for i in progress_bar:\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        epoch_cost = 0\n",
    "        \n",
    "        for j in range(0, n_samples, batch_size):\n",
    "            batch_indices = indices[j:min(j + batch_size, n_samples)]\n",
    "            X_batch = X[batch_indices]\n",
    "            y_batch = y[batch_indices]\n",
    "            \n",
    "            activations = forward_propagation(X_batch, parameters)\n",
    "            gradients = back_propagation(y_batch, parameters, activations)\n",
    "            parameters = update(gradients, parameters, learning_rate)\n",
    "            \n",
    "            output = activations[f'A{len(hidden_layers) + 1}']\n",
    "            batch_cost = -np.mean(y_batch.T * np.log(output + 1e-8) + \n",
    "                                (1 - y_batch.T) * np.log(1 - output + 1e-8))\n",
    "            epoch_cost += batch_cost * len(batch_indices)\n",
    "        \n",
    "        epoch_cost /= n_samples\n",
    "        costs.append(epoch_cost)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            activations = forward_propagation(X, parameters)\n",
    "            output_layer_activation = activations[f'A{len(hidden_layers) + 1}']\n",
    "            accuracy = np.mean((output_layer_activation.T >= 0.5) == y)\n",
    "            progress_bar.set_postfix({'Cost': f'{epoch_cost:.4f}', 'Accuracy': f'{accuracy:.2%}'})\n",
    "    \n",
    "    return parameters, costs\n",
    "   # Load the processed features\n",
    "print(\"Loading processed features...\")\n",
    "with open('processed_features.pkl', 'rb') as f:\n",
    "    X, y = pickle.load(f)\n",
    "\n",
    "# Print diagnostic information\n",
    "print(\"\\nDiagnostic information:\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"X dtype:\", X.dtype)\n",
    "print(\"y dtype:\", y.dtype)\n",
    "\n",
    "# Train the model\n",
    "parameters, costs = deep_learning(\n",
    "    X, \n",
    "    y, \n",
    "    hidden_layers=(256, 128, 64),\n",
    "    learning_rate=0.001,\n",
    "    n_iter=500,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "print(\"\\nSaving model parameters...\")\n",
    "with open('model_parameters.pkl', 'wb') as f:\n",
    "    pickle.dump((parameters, costs), f)\n",
    "\n",
    "print(\"Training completed and model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "242531ab-a1bc-4b1b-9fa6-51caa326bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    activations = forward_propagation(X, parameters)\n",
    "    C = len(parameters) // 2\n",
    "    Af = activations['A' + str(C)]\n",
    "    return Af >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f164b3cd-4dc2-4239-80c0-11f18e668b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Female\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "with open('model_parameters.pkl', 'rb') as f:\n",
    "    parameters, costs = pickle.load(f)\n",
    "\n",
    "# Test the model\n",
    "image_path = 'content/male_faces/1 (10).png'\n",
    "cnn_model = CNNPreprocessor()\n",
    "\n",
    "cnn_features = process_image_cnn(image_path, cnn_model)\n",
    "if cnn_features is not None:\n",
    "    # Predict using the trained model\n",
    "    output = forward_propagation(cnn_features.T, parameters)\n",
    "    prediction = (output[f'A{len(parameters) // 2}'] > 0.5).astype(int)\n",
    "    print(\"Prediction:\", \"Male\" if prediction == 1 else \"Female\")\n",
    "else:\n",
    "    print(\"Failed to process the test image.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05babe02-0735-430b-bb78-ce0c9338feb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
